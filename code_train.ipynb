{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Đọc dữ liệu\n",
    "directory = \"Processed data txt/\" # dữ liệu video train đã được tiền xử lý\n",
    "test_directory = \"Processed test/\" # dữ liệu video test đã được tiền xử lý\n",
    "\n",
    "n_frames = 20 # số frame gom vào một record\n",
    "\n",
    "def train_loader(directory,batch_size=128): # trong trường hợp dữ liệu quá lớn, load từng phần bằng generator\n",
    "    txt_data = os.listdir(directory)\n",
    "    folders = [folder for folder in txt_data if not folder.endswith(\".txt\")]\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    while True:\n",
    "        count_label = 0\n",
    "        for folder in folders:\n",
    "            sub_directory = os.path.join(directory,folder)\n",
    "            file_list = os.listdir(sub_directory)\n",
    "            for file in file_list:\n",
    "                file_path = os.path.join(sub_directory,file)\n",
    "                df = pd.read_csv(file_path)\n",
    "                dataset = df.iloc[:,1:].values\n",
    "                n_sample = len(dataset)\n",
    "                for i in range(n_frames, n_sample):\n",
    "                    X_train.append(dataset[i-n_frames:i,:])\n",
    "                    y_train.append(count_label)\n",
    "                    if len(y_train) == batch_size:\n",
    "                        yield np.array(X_train), np.array(y_train)\n",
    "                        X_train = []\n",
    "                        y_train = []\n",
    "            count_label += 1\n",
    "            if count_label==22:\n",
    "                count_label=0\n",
    "\n",
    "def load_all(directory): # trong trường hợp dữ liệu nhỏ hoặc vừa phải, load toàn bộ để đẩy nhanh tốc độ train\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    txt_data = os.listdir(directory)\n",
    "    folders = [folder for folder in txt_data if not folder.endswith(\".txt\")]\n",
    "    count_label = 0\n",
    "    print(folders)\n",
    "    label_dict = {}\n",
    "    for folder in folders:\n",
    "        sub_directory = os.path.join(directory,folder)\n",
    "        file_list = os.listdir(sub_directory)\n",
    "        for file in file_list:\n",
    "            file_path = os.path.join(sub_directory,file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataset = df.iloc[:,1:].values\n",
    "            n_sample = len(dataset)\n",
    "            for i in range(n_frames, n_sample):\n",
    "                X_train.append(dataset[i-n_frames:i,:])\n",
    "                y_train.append(count_label)\n",
    "        label_dict[count_label] = folder\n",
    "        count_label += 1\n",
    "    return np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dữ liệu toàn bộ\n",
    "X_train, y_train = load_all(directory)\n",
    "X_test, y_test = load_all(test_directory)\n",
    "print(X_train.shape,X_test.shape)\n",
    "num_train = y_train.shape[0]\n",
    "num_val = y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model LSTM 4 lớp với số unit [44, 88, 44, 22], kết hợp với BatchNormalization và Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense,Dropout,BatchNormalization,Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "input_shape = (20,132)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units = 44,\n",
    "                activation=\"tanh\",\n",
    "                kernel_regularizer=regularizers.l2(1e-4),\n",
    "                return_sequences=True,\n",
    "                input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(units = 88,\n",
    "                activation=\"tanh\",\n",
    "                kernel_regularizer=regularizers.l2(1e-4),\n",
    "                return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(units = 44,\n",
    "                activation=\"tanh\",\n",
    "                kernel_regularizer=regularizers.l2(1e-4),\n",
    "                return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(units = 22,\n",
    "                activation=\"tanh\",\n",
    "                kernel_regularizer=regularizers.l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(22,activation=\"softmax\"))\n",
    "model.build(input_shape=(None,20,132))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt checkpoint và lr-scheduler giảm dần learning_rate theo từng bước\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=\"best_checkpoint_LSTM_4_44-88-44-22.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_weights_only=False,\n",
    "    mode=\"max\",\n",
    "    save_best_only=True\n",
    ")\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n",
    "lr_max = 0.001\n",
    "reduct_step = 1\n",
    "def lr_sch(epoch):\n",
    "    return lr_max*0.8**(epoch//reduct_step)\n",
    "lr_schedule = LearningRateScheduler(lr_sch,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train và lưu lại model\n",
    "history = model.fit(X_train,y_train,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_data = (X_test,y_test),\n",
    "          callbacks=[checkpoint_callback,lr_schedule])\n",
    "model.save(\"model_remake_LSTM_4_44-88-44-22.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá cuối cùng dựa trên tập test, vẽ confusion matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis = 1)\n",
    "f1 = f1_score(y_test,y_pred,average=\"weighted\")\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print(\"F1 score: \" + str(f1))\n",
    "print(\"Accuracy_score: \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=False, fmt=\"d\", cmap=\"viridis\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
